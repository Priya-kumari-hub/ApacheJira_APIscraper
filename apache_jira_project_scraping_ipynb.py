# -*- coding: utf-8 -*-
"""apache_jira_project_scraping_ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iRVRjyl7eiSvGUizkLCJvtK7yMyMbEI8
"""

!pip install requests tqdm

import requests
import json
from tqdm import tqdm

BASE_URL = "https://issues.apache.org/jira/rest/api/2/search"
PROJECTS = ["SPARK", "HADOOP", "KAFKA"]

def fetch_issues(project_key, start=0, max_results=50):
    """Fetch issues from a Jira project with pagination + retry."""
    params = {
        "jql": f"project={project_key}",
        "startAt": start,
        "maxResults": max_results
    }

    for retry in range(3):
        try:
            r = requests.get(BASE_URL, params=params, timeout=10)

            # Too many requests
            if r.status_code == 429:
                print("Rate limit hit. Waiting 5 seconds...")
                import time; time.sleep(5)
                continue

            # Server error
            if r.status_code >= 500:
                continue

            return r.json()

        except Exception as e:
            print("Network error, retrying:", e)

    return {"issues": []}

def scrape_project(project_key):
    print(f"\nğŸ” Scraping project: {project_key}")

    all_issues = []
    start = 0
    total = 1

    while start < total:
        data = fetch_issues(project_key, start)
        issues = data.get("issues", [])
        total = data.get("total", 0)

        all_issues.extend(issues)
        start += 50

        print(f"Fetched {len(all_issues)}/{total} issues...")

    return all_issues

def convert_to_jsonl(issues, output_file):
    """Convert Jira issues into JSONL format"""
    with open(output_file, "w", encoding="utf-8") as f:
        for issue in issues:
            fields = issue.get("fields", {})

            obj = {
                "id": issue.get("key"),
                "title": fields.get("summary", ""),
                "project": fields.get("project", {}).get("key"),
                "status": fields.get("status", {}).get("name"),
                "priority": fields.get("priority", {}).get("name") if fields.get("priority") else None,
                "reporter": fields.get("reporter", {}).get("displayName") if fields.get("reporter") else None,
                "description": fields.get("description", ""),
                "comments": [
                    c.get("body", "") for c in fields.get("comment", {}).get("comments", [])
                ],
                "task_summarization": f"Summarize the issue: {fields.get('summary', '')}",
                "task_classification": f"Classify issue priority: {fields.get('summary', '')}"
            }

            f.write(json.dumps(obj) + "\n")

    print(f"Saved {output_file}")

# --- MAIN SCRIPT ---

all_data = {}

for project in PROJECTS:
    issues = scrape_project(project)
    all_data[project] = issues
    convert_to_jsonl(issues, f"{project.lower()}_jira.jsonl")

print("\nğŸ‰ Done! JSONL files created for all 3 projects.")

import pandas as pd

df = pd.read_json("spark_jira.jsonl", lines=True)
df.head()

from google.colab import files
files.download("spark_jira.jsonl")
files.download("hadoop_jira.jsonl")
files.download("kafka_jira.jsonl")

